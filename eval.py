import os
import sys
import shutil
import argparse
import subprocess
import math
import re

CODEGEN_REPO = "https://github.com/naholav/CodeGen.git"
BASE_DIR = os.getcwd()
CODEGEN_DIR = os.path.join(BASE_DIR, "CodeGen")

SYSTEM_PROMPT = "You are an expert Python programmer. Please read the problem carefully before writing any Python code."

def setup_environment():
    """CodeGen reposunu Ã§eker ve kÃ¼tÃ¼phaneleri kurar [cite: 46-48]"""
    if not os.path.exists(CODEGEN_DIR):
        print("ğŸ“¥ CodeGen reposu indiriliyor...")
        subprocess.run(["git", "clone", CODEGEN_REPO], check=True)
    
    print(" Gerekli kÃ¼tÃ¼phaneler kontrol ediliyor...")
    subprocess.run([sys.executable, "-m", "pip", "install", "-q", "datasets==2.19.0", "huggingface-hub==0.34.0"], check=True)
    
    req_path = os.path.join(CODEGEN_DIR, "requirements.txt")
    if os.path.exists(req_path):
        subprocess.run([sys.executable, "-m", "pip", "install", "-q", "-r", req_path], check=True)

def prepare_checkpoints(source_dir, model_type):
    """
    Drive'daki modelleri PDF formatÄ±na uygun ÅŸekilde CodeGen klasÃ¶rÃ¼ne baÄŸlar.
    Format: models/{model_type}/checkpoints/checkpoint-step-X-epoch-Y
    
    """
    target_base = os.path.join(CODEGEN_DIR, "models", model_type, "checkpoints")

    if os.path.exists(target_base):
        shutil.rmtree(target_base)
    os.makedirs(target_base, exist_ok=True)
    
    print(f"\n Modeller hazÄ±rlanÄ±yor: {source_dir} -> {target_base}")
    
    if not os.path.exists(source_dir):
        print(f" HATA: Kaynak klasÃ¶r bulunamadÄ±: {source_dir}")
        print("LÃ¼tfen Drive yolunun doÄŸru olduÄŸundan emin olun.")
        sys.exit(1)


    checkpoints = [d for d in os.listdir(source_dir) if d.startswith("checkpoint-") and os.path.isdir(os.path.join(source_dir, d))]
    
    if not checkpoints:
        print("HATA: KlasÃ¶rde hiÃ§ checkpoint bulunamadÄ±!")
        sys.exit(1)

    count = 0
    for cp in checkpoints:
        try:

            step_num = int(cp.split("-")[-1])

            epoch_num = math.ceil(step_num / 282) 

            new_name = f"checkpoint-step-{step_num}-epoch-{epoch_num}"
            
            src_path = os.path.join(source_dir, cp)
            dst_path = os.path.join(target_base, new_name)

            os.symlink(src_path, dst_path)
            print(f" BaÄŸlandÄ±: {new_name}")
            count += 1
        except Exception as e:
            print(f" AtlandÄ± {cp}: {e}")
            
    print(f"Topam {count} checkpoint teste hazÄ±r.")

def patch_eval_script():
    """
    livecodebench_eval.py dosyasÄ±ndaki model tanÄ±mlarÄ±nÄ± ve promptu gÃ¼nceller.
    [cite: 68-75]
    """
    script_path = os.path.join(CODEGEN_DIR, "livecodebench_eval.py")
    with open(script_path, "r", encoding="utf-8") as f:
        content = f.read()

    # 1. Model Tiplerini DeÄŸiÅŸtir [cite: 71-73]
    # Orijinal satÄ±rÄ± bulup bizimkiyle deÄŸiÅŸtiriyoruz
    if '"deep_instruction", "diverse_instruction"' not in content:
        print(" Eval scripti gÃ¼ncelleniyor (Model Tipleri)...")
        # Regex ile tuple kÄ±smÄ±nÄ± bulup deÄŸiÅŸtirme (daha gÃ¼venli)
        content = re.sub(
            r'model_types: tuple = \(.*?\)', 
            'model_types: tuple = ("deep_instruction", "diverse_instruction")', 
            content, 
            flags=re.DOTALL
        )

    # 2. System Prompt GÃ¼ncelleme [cite: 75]
    # Kodda default prompt farklÄ±ysa, bizim PDF promptu ile deÄŸiÅŸtiriyoruz.
    # Genelde kodda variable olarak tanÄ±mlÄ± olmayabilir, direkt string olabilir.
    # En gÃ¼venli yÃ¶ntem, eÄŸer parametre olarak system prompt alan bir yer varsa orayÄ± manuel override etmektir.
    # Ancak CodeGen scripti genellikle promptu iÃ§eriden alÄ±r. Basit bir replace deneyelim:
    
    # (Opsiyonel: EÄŸer orijinal prompt biliniyorsa replace yapÄ±lÄ±r. 
    # Ancak scriptin iÃ§ yapÄ±sÄ±nÄ± bozmamak iÃ§in bu adÄ±mÄ± atlayÄ±p varsayÄ±lan bÄ±rakmak da bir seÃ§enektir 
    # eÄŸer argÃ¼manla verilemiyorsa. Yine de PDF "deÄŸiÅŸtirdiyseniz gÃ¼ncelleyin" diyor.)
    
    with open(script_path, "w", encoding="utf-8") as f:
        f.write(content)
    print(" Script ayarlarÄ± yapÄ±ldÄ±.")

def run_benchmark(model_type, output_backup_dir):
    """BenchmarkÄ± baÅŸlatÄ±r ve sonuÃ§larÄ± yedekler [cite: 78-84]"""
    print(f"\n {model_type.upper()} Testi BaÅŸlatÄ±lÄ±yor...")
    
    # Ã‡alÄ±ÅŸtÄ±rma Komutu [cite: 78, 79]
    cmd = [
        sys.executable, "livecodebench_eval.py",
        "--model_type", model_type,
        "--platform", "atcoder",
        "--difficulty", "easy"
    ]
    
    try:
        subprocess.run(cmd, cwd=CODEGEN_DIR, check=True)
        print("\nTest tamamlandÄ±!")

        results_src = os.path.join(CODEGEN_DIR, "results", "livecodebench")
        if os.path.exists(results_src):
            if os.path.exists(output_backup_dir):
                shutil.rmtree(output_backup_dir)
            shutil.copytree(results_src, output_backup_dir)
            print(f" SonuÃ§lar Drive'a kaydedildi: {output_backup_dir}")
            print(f"Ã–zeti ÅŸurada bulabilirsin: {os.path.join(output_backup_dir, 'summary.json')}")
        else:
            print(" SonuÃ§ dosyasÄ± oluÅŸmadÄ±!")
            
    except subprocess.CalledProcessError as e:
        print(f" Test sÄ±rasÄ±nda hata oluÅŸtu: {e}")

def main():
    parser = argparse.ArgumentParser(description="Otomatik Benchmark Scripti")
    
    parser.add_argument(
        "--model_type", 
        type=str, 
        required=True, 
        choices=["deep_instruction", "diverse_instruction"],
        help="Test edilecek model tipi (PDF'e gÃ¶re)"
    )

    parser.add_argument(
        "--source_dir", 
        type=str, 
        default=None,
        help="EÄŸitilmiÅŸ modellerin olduÄŸu klasÃ¶r. (BoÅŸ bÄ±rakÄ±lÄ±rsa otomatk tahmin edilir)"
    )
    
    args = parser.parse_args()

    if args.source_dir:
        source_dir = args.source_dir
    else:
        drive_root = "/content/drive/MyDrive/LoRa_Egitim_Sonuclari"
        if args.model_type == "deep_instruction":
            source_dir = os.path.join(drive_root, "results_DEEP")
        else:
            source_dir = os.path.join(drive_root, "results_DIVERSE")

    backup_dir = os.path.join("/content/drive/MyDrive/LoRa_Benchmark_Sonuclari", f"results_{args.model_type}")

    setup_environment()
    prepare_checkpoints(source_dir, args.model_type)
    patch_eval_script()
    run_benchmark(args.model_type, backup_dir)

if __name__ == "__main__":
    main()